# 四种方法对比

## 1. bert
加载已训练好的bert权重，进行分类。
- 优点
    - 语义理解能力强：bert基于transformer实现，可以捕获深层的语义关系
    - 训练时长友好，准确性好：可基于已经训练好的权重进行微调
    - 泛化能力好：可利用预训练模型的知识
- 缺点：
    - 推理速度慢，消耗计算资源

## 2. prompt
结合检索增强生成(RAG)的推理分类。通过查找与输入文本最相似的10个文本，组成prompt。调用大模型API进行分类。
- 优点：
    - 动态生成promt：根据输入动态调整提示内容
    - 语义理解能力强：大模型通过大量语料的训练，学习到很多通用语义信息
    - 适应性好：可处理复杂任务
    - 可解释好：通过相似性筛选样例，提供决策依据
    - zero-shot learning：无需额外训练
- 缺点：
    - 调用API需要消耗成本
    - 暴露敏感信息

## 3. regex_rule
基于预先定义的规则来进行模型匹配
- 优点：
    - 无需训练过程
    - 规则明确
    - 处理速度快
    - 资源消耗少
    - 结果确定性强
- 缺点：
    - 匹配规则覆盖范围有限
    - 需人工维护：需要耗费维护成本
    - 不够灵活：泛化能力有限
    - 不易扩展：新规则可能影响现有规则

## 4. tfidf_ml
通过TF-IDF特征和机器学习模型进行分类。
- 优点：
    - 特征提取，可解释性较好
    - 模型更轻量，资源消耗少
- 缺点：
    - 效果依赖于特征工程
    - 语义理解有限