# 模型对比分析
## 1.bert 预训练语言模型
+ 核心是基于transformer的双向编码器

|    |                                       |
|:--:|:-------------------------------------:|
| 优点 |          擅长处理上下文理解<br/>准确率高           |
| 缺点 | 计算密集，需要GPU<br/>推理速度较慢<br/>小数据集容易发生过拟合 |

## 2.prompt 提示词工程
+ 核心是利用LLM和提示词工程实现意图分类

|    |                                            |
|:--:|:------------------------------------------:|
| 优点 | 无需重新训练模型<br/>使用灵活<br/>利用LLM的语义理解，处理复杂模糊的意图 |
| 缺点 |       依赖外部API，成本高，延迟大<br/>容易受到提示词攻击        |

## 3.regex_rule 正则
+ 核心是利用正则表达式的规则匹配分类类型

||                             |
|:-:|:---------------------------:|
|优点|       零训练，确定性高<br/>解释性强，快速       |
|缺点| 泛化性很弱<br/>维护规则费力<br/>容易忽略语义 |

## 4.tfidf_ml 基于TF-IDF和传统机器学习
+ 核心是利用TF-IDF提取特征，然后使用预训练机器模型分类

|    |                                           |
|:--:|:-----------------------------------------:|
| 优点 |           轻量级，快速<br/>无需GPU，容易部署           |
| 缺点 | 语义浅层，无法处理同义词或上下文<br/>对噪声敏感<br/>需要大量标注数据训练 |