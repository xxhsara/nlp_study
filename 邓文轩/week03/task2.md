# 四个模型的优缺点

## TFIDF

优点：
- 可解释性强
- 不受语序影响
- 提前算好词表里每个词的tfidf，之后计算一个句子的tfidf分数速度快，轻量级

缺点：
- 受数据不平衡的影响
- 词袋模型，无法提取句子语义
- 无法计算词的相似度，若增加新的文档类别需要重新计算tfidf
- 分值未归一化，长文本的tfidf分数会大于短文本（加和问题）
- 需要一定量训练（统计）样本才能计算

## 正则表达式

优点：
- 规则性强、意图明确的指令准确率高
- 基于规则，不需要训练数据
- 使用简单

缺点：
- 泛化性差
- 无法处理复杂的自然语言

## BERT

优点：
- 能理解语义信息
- 使用预训练模型作为encoder，训练成本较低
- 比大模型更轻量级

缺点：
- 如果新增类别需要重训分类模型
- 处理的文本长度有限，长度小于大模型
- 需要训练数据

## 大模型

优点：
- 无需训练，直接调api
- 能力强大，效果好，可以理解语义


缺点：
- 本地部署需要硬件资源，成本较高
- 响应速度慢
- 模型可能会出现幻觉，需要编写好prompt
