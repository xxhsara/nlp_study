### 1. 正则匹配模型 (Regex Rule)

- **核心逻辑**：
  - **硬匹配**。它不需要“思考”，也不涉及概率。它只看你的句子有没有命中预先写好的关键词列表（如 `["打开", "车窗"]`）。
- **优势**：
  - **速度极快**：响应时间在微秒级，基本不消耗算力，对车载芯片极度友好。
  - **绝对可控**：对于高风险指令（如“打开油箱盖”、“立即刹车”），它是最安全的，不会出现 AI 的“幻觉”。
  - **冷启动**：不需要任何训练数据，写好规则就能上线。
- **劣势**：
  - **无泛化能力**：你定义了“打开”，用户说“开启”，它就不认识了。
  - **维护地狱**：随着意图变多，规则会互相冲突（比如“打开车窗”和“打开天窗”），代码维护成本指数级上升。
  - **不懂否定句**：代码逻辑很简单，用户说“**别**打开空调”，它依然会识别为“打开空调”。

------

### 2. TF-IDF + 机器学习模型 (Statistical ML)

- **核心逻辑**：
  - **关键词权重**。它不关心句子的意思，只关心“词频”。它认为如果在“空调”类别里“冷”字出现得多，那么以后看到“冷”就归类为空调。依赖 `jieba` 分词和 `cn_stopwords`（停用词），是一个典型的“分词 -> 向量化 -> 分类”流水线。
- **优势**：
  - **轻量高效**：模型文件通常只有几 MB，CPU 推理速度极快（<10ms），非常适合车载端的长尾指令处理。
  - **模糊匹配**：比正则强，即使用户说法稍微变一点（只要核心词在），它也能通过统计概率识别出来。
  - **可解释性**：你可以知道哪个词起到了决定性作用。
- **劣势**：
  - **丢失语序信息**：它用的是“词袋模型”（Bag of Words）。对它来说，“猫抓老鼠”和“老鼠抓猫”是一模一样的，因为它只看有什么词，不看词的顺序。
  - **特征工程繁琐**：极其依赖停用词表的质量。如果“打开”被当成了停用词删掉了，那很多指令就没法识别了。

------

### 3. BERT 模型 (Deep Learning)

- **核心逻辑**：
  - **深度语义理解**。它通过 `Self-Attention`（自注意力机制）同时看整句话。它不仅认识词，还理解词与词之间的关系（上下文）。基于 `Transformers` 架构，使用预训练模型 + 微调（Fine-tuning）。它能理解“把温度调高点”和“有点冷”是同一个意思。
- **优势**：
  - **高准确率**：在分类任务上，它是目前工业界的主力，准确率通常能轻松达到 95% 以上。
  - **强泛化能力**：它“懂”中文。即使用户用了没见过的说法，只要语义接近，它都能识别。
  - **理解上下文**：能区分多义词（比如“苹果”在“吃苹果”和“苹果手机”里的区别）。
- **劣势**：
  - **算力昂贵**：需要 GPU 或高性能 CPU 才能跑得快。
  - **黑盒**：很难解释为什么它分错了，调试比较困难。

------

### 4. LLM 大模型 (Generative AI)

- **核心逻辑**：
  - **推理与生成**。它不是在做分类，而是在“做阅读理解题”。你给它几个例子（Few-shot），它模仿着推理出新问题的答案。使用了 `RAG`（检索增强生成）技术，先检索相似历史例子，再通过 Prompt 让 LLM 续写答案。
- **优势**：
  - **理解能力最强**：能处理极其复杂的长难句、多意图、甚至带有情绪的指令。
  - **零样本学习**：不需要训练，只要在数据库里加一条例子，它立马学会新意图，迭代速度极快。
  - **人性化**：除了识别意图，还能顺便生成回复。
- **劣势**：
  - **速度慢**：代码通过 HTTP 调用云端接口，延迟通常在 1秒以上，完全无法满足项目要求的“<400ms”。
  - **不可控（幻觉）**：它可能会自作聪明地输出一些不在候选列表里的答案，或者废话太多。
  - **成本高**：Token 是要钱的，或者本地部署需要昂贵的显卡。
