我将从loss数值和歌词逻辑性上分析RNN、GRU、LSTM三种循环模型的特点

从loss数值上看，LSTM表现最好，多次下探到 **0.41 - 0.52** 区间；RNN第二，在 **0.49 - 0.58** 之间；GRU相对最高，徘徊在 **0.55 - 0.68**。

但是从歌词逻辑上看：

* RNN的输入是最为“语无伦次”的，说明了他的记忆能力最差，无法维持一个句子的完整性，是梯度消失带来的结果。
* GRU表现好点，出现了整句的完整逻辑内容，但是上下句的关系是混乱的，不如LSTM表现好。
* LSTM基本复刻了完整的歌词，把《一路向北》的歌词机构记的很牢，但是只能说复制得很好，没有表现出创造力。